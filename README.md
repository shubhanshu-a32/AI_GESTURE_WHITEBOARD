# ğŸ¨ AI Gesture Whiteboard

![License](https://img.shields.io/badge/license-MIT-blue.svg) ![React](https://img.shields.io/badge/React-20232A?style=flat&logo=react&logoColor=61DAFB) ![Node.js](https://img.shields.io/badge/Node.js-339933?style=flat&logo=nodedotjs&logoColor=white) ![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white) ![OpenCV](https://img.shields.io/badge/OpenCV-5C3EE8?style=flat&logo=opencv&logoColor=white)

> An interactive whiteboard application that magically transforms your hand gestures into digital art using AI.

## ğŸŒŸ Overview

**AI Gesture Whiteboard** leverages the power of computer vision to create a touchless drawing experience. By tracking hand movements in real-time, it allows users to draw and create shapes on a digital canvas simply by moving their fingers in the air.

Built with **React** for the frontend, **Node.js** for the backend, and **OpenCV & MediaPipe** for the AI processing engine.

## ğŸš€ Key Features

*   **Real-time Hand Tracking**: Precision tracking using MediaPipe.
*   **Gesture Recognition**: Detects "Draw" gestures and specific shapes.
*   **Instant Shape Rendering**: Automatically perfects circles and rectangles.
*   **Low Latency**: Optimized Socket.IO communication for smooth drawing.

## ğŸ› ï¸ Tech Stack

*   **Frontend**: React, Canvas API
*   **Backend**: Node.js, Express, Socket.IO
*   **AI Engine**: Python, OpenCV, MediaPipe, Python-SocketIO

## ğŸ“¦ Installation & Usage

### 1. Client & Server (JavaScript)

Start the web application and the websocket server.

```bash
# Install dependencies for both client and server
npm install

# Run both in development mode
# Open two terminals or run sequentially if needed
cd client && npm run dev
cd server && npm run dev
```

### 2. AI Engine (Python)

Set up the computer vision engine.

```bash
# Navigate to the AI engine directory
cd ai-engine

# Create a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows use `venv\Scripts\activate`

# Install dependencies
pip install -r requirements.txt

# Start the AI Tracker
python src/main.py
```

## ğŸ“‚ Project Structure

```bash
AI_GESTURE_WHITEBOARD
â”œâ”€â”€ ğŸ§  ai-engine           # Python-based Computer Vision Logic
â”‚   â”œâ”€â”€ src
â”‚   â”‚   â”œâ”€â”€ gestures.py
â”‚   â”‚   â”œâ”€â”€ hand_tracker.py
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ shape_detector.py
â”‚   â”‚   â””â”€â”€ websocket_client.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ ğŸ’» client              # React Frontend
â”‚   â”œâ”€â”€ src
â”‚   â”‚   â”œâ”€â”€ components
â”‚   â”‚   â”œâ”€â”€ hooks
â”‚   â”‚   â”œâ”€â”€ pages
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ index.css
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ ğŸ”Œ server              # Node.js WebSocket Server
    â”œâ”€â”€ src
    â”‚   â”œâ”€â”€ index.ts
    â”‚   â”œâ”€â”€ socket.ts
    â”‚   â””â”€â”€ types.ts
    â””â”€â”€ package.json
```

## â¤ï¸ Show Your Support

If you find this project interesting, please give it a â­ï¸ on GitHub!

Created by **Shubhanshu Upadhyay**